Areas for Improvement and Potential Issues

Despite the overall solidity, there are a few areas to consider for improvement or careful attention as you move forward:

Support for Unicode Identifiers: Currently, the identifier rule is limited to ASCII letters and numbers

. However, SysML models might include international characters in names (for example, the spec and tests hint at supporting Unicode in qualified names – e.g., a test uses Japanese characters in a package name). You will likely want to extend the identifier rule to include Unicode letters (and possibly combining marks) so that names like パッケージ::部品::属性 are parsed as valid identifiers/qualified names. Pest doesn’t have a built-in Unicode alphabetic class, but you can manually include Unicode ranges or use the [:XID_Start:] / [:XID_Continue:] character classes if Pest supports them (or a custom sub-rule for “letter”). At minimum, consider allowing any letter from the Unicode categories as a start character and letters/digits as continuation. This will align the parser with the spec’s intent for internationalization. Not doing so will cause the parser to reject otherwise valid model identifiers that contain non-ASCII characters. Since your roadmap already flags adding Unicode support in the QualifiedName/sysml-id handling, the grammar should follow suit

.

String and Quoted Name Content Restrictions: As noted, the string_value and quoted_name rules use ANY for content

. This means newline characters are allowed within them. If the SysML textual syntax does not allow multi-line strings or names, you should refine these rules. For example, you could use a construct like (!"\"" ~ !"\n" ~ ANY)* for strings to exclude raw newlines. If multi-line strings are allowed (perhaps to support long documentation text in quotes), then it’s fine as-is. Just be mindful that ANY will also allow unprintable control characters, so you might want to restrict to visible characters and spaces explicitly. Similarly, for quoted_name (identifiers in single quotes), allowing newlines or certain symbols might not be intended. It could be safer to use a character class that includes letters, digits, spaces, and common punctuation, while excluding the quote and control chars. This will prevent odd edge cases (like a quoted name breaking across lines) that the spec likely doesn’t anticipate.

Parsing Performance Considerations: PEG grammars can sometimes encounter performance pathologies if alternatives lead to a lot of backtracking. Your grammar is mostly well-factored to avoid this – for instance, ordering the longest keywords first and using atomic rules will cut down unnecessary backtracking. One spot to keep in mind is the use of optional and repeated empty matches. For example, basic_usage_prefix can match nothing (all its components are optional)

. In practice this isn’t dangerous because it’s not in a loop by itself; it’s always followed by a required token (like a attribute_token in an attribute_usage rule, etc.). However, always be cautious that no rule like (X?)* exists – I did not spot any obvious ones. The grammar seems to avoid that (you use concrete separators in repeats). If performance does become an issue for very large models, one could consider optimizing some of the more complex lookahead usage. For example, the negative lookahead for end_usage_prefix (!end_usage_keyword)

is necessary to disambiguate end as a standalone prefix vs part of a compound (like end action), but such lookahead checks can marginally slow parsing. This is probably negligible unless a file is extremely large. In general, Pest is known to be reasonably efficient for deterministic grammars like this, so I’d expect performance to be acceptable. Just ensure your test corpus includes some larger models to benchmark parse time and stack usage. The roadmap’s plan to include benchmarks is a good idea here.

Grammar Maintenance and Generation: You mentioned that the grammar is generated from the SysML/KerML Xtext specs at build time (as noted in the README

). Ensuring this generation process is robust will be important for maintainability. Right now, the Pest grammar file is quite large (~2500+ lines) and a bit unwieldy to edit by hand – which is fine if it’s auto-generated or systematically derived. If you haven’t already, consider modularizing the grammar into logical sections (e.g., one file for expressions, one for state machines, one for structure/behavior elements, etc.) and then combining them, or use a build script to pull in the latest Xtext and translate it. This way, as the SysML spec evolves or clarifies edge cases, you can update the grammar more easily. The current structure already has logical groupings (with comments separating sections), so splitting them in generation wouldn’t be too hard. In Jade’s fork, for instance, expressions were separated into a kerml_expressions.pest file

– that kind of separation can make the grammar easier to manage conceptually.

Completeness and Spec Alignment: While the grammar covers most constructs, keep an eye on any remaining 20% of models that aren’t parsing. Those likely expose either grammar bugs or unimplemented features. Possible culprits could be extremely complex scenarios or recently added syntax in the SysML v2 spec. For example, ensure that all relationship types and special import/filter cases are handled – the grammar does include membership vs namespace import, filter expressions on imports

, and dependency relationships. One thing to double-check is the “select” or “filter” operations on collections (sometimes written as a sequence of [ ] with expressions). I see that filter_package and filter_package_member are defined for import filters, and the general collection filter ([ expression ]) is present as part of primary expression extensions

. This suggests you have covered it. If certain models fail, try to isolate what grammar rule isn’t handling them and add tests for those patterns. Given the breadth of the grammar, I suspect only minor tweaks are needed to reach full coverage.

Error Handling and Diagnostics: Right now, the grammar is focused on acceptance (parsing valid models). As you improve it, you might also consider how to make error messages more helpful for users of the parser. Pest by default will report something like “expected X” at a location. Because of the large number of rules, the default expectations might be a bit cryptic. One way to improve this is using Pest’s expected() syntax in strategic places to label certain alternatives. For example, if a construct is very specific, you could do foo_rule = { alt1 | alt2 | expected("a Foo element") } – so if neither alt1 nor alt2 matches, the error says “expected a Foo element” instead of a raw list of tokens. This isn’t critical for the parser’s functionality, but it will greatly help when you build your LSP server or command-line tooling, as users can get clearer syntax error messages. It’s something to keep in mind for the future (perhaps in phase 2c or 3 of your roadmap).

Minor Consistency Tweaks: There are a few minor stylistic inconsistencies that don’t necessarily break anything but are worth noting. For instance, in the rules like defined_by_token = @{ colon | (defined_token ~ space ~ by_token) }:contentReference[oaicite:52]{index=52}, the inclusion of an explicit spaceliteral might be unnecessary because global WHITESPACE skipping would already allow whitespace betweendefinedandby. However, by writing it this way, you effectively require **at least one space and no newline** (since spacematches only the space character) between “defined” and “by”. This matches how the phrase “defined by” likely appears in the spec (as two words, probably on the same line). It’s not wrong – just be aware that something like a newline betweendefinedandbywould fail to parse here, even though conceptually one might think it could be equivalent. Similar patterns exist fortyped_token ~ space ~ by_token`

. If the spec explicitly intends those as a fixed two-word phrase, keep it as is. If not, you could loosen it to allow any whitespace. This is a very minor point, but mentioning it for completeness.

Testing and Coverage: It sounds like you’re already building a comprehensive test suite. The provided sysml-spec-tests with coverage tracking is an excellent idea – mapping parsed elements to the expected set of model element types

. As you add more tests, you’ll naturally shake out any lingering issues. One improvement to testing might be to include some intentionally malformed inputs to ensure the grammar fails in the expected way (and doesn’t, say, parse something incorrect as a partial structure). Given the complexity of the grammar, having tests for negative cases (invalid syntax) can be as informative as tests for valid cases. This can guard against the grammar being too permissive in places.
